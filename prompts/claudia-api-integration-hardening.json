{
  "$schema": "https://claudia.contrived.com/schemas/prompt.schema.json",
  "id": "claudia-api-integration-hardening",
  "title": "Harden Claudia API Integration",
  "description": "Fix edge cases and improve robustness in the frank_bot Claudia client and action handlers",
  "authors": [
    {"name": "Sean", "type": "human"},
    {"name": "claude-4.6-opus", "type": "model"}
  ],
  "createdAt": "2026-02-20T02:00:00Z",
  "status": "ready",
  "tags": ["claudia", "api", "reliability", "error-handling"],
  "content": "# Harden Claudia API Integration\n\n## Context\n\nThis prompt assumes the agent has read:\n- This repo's AGENTS.md\n- ~/dev/homelab-infra/ECOSYSTEM.md (for cross-repo context)\n- ~/dev/claudia/AGENTS.md (for Claudia API context)\n\nThe frank_bot ↔ Claudia integration enables a chat → create prompt → execute prompt pipeline, driven by ChatGPT via OpenAI Actions. The integration is architecturally sound (clean separation between `services/claudia_client.py` for HTTP and `actions/claudia.py` for business logic), but a production incident revealed several edge cases that need hardening.\n\n## Background: The Incident\n\nThe fountain-pens repo pipeline failed because:\n1. ChatGPT called `create_prompt` with a stale chat_id that no longer existed → 404\n2. ChatGPT retried by creating a fresh chat, then immediately calling `create_prompt` — but the Claudia bat-side had an ordering bug (now fixed in claudia repo) where the chat was deleted before the prompt-to-chat linkage was recorded\n3. The prompt was generated successfully but the bookkeeping was lost\n\nThe bat-side ordering bug is fixed. This prompt addresses the remaining frank_bot-side improvements.\n\n## Requirements\n\n### 1. Add chat status validation before prompt creation\n\n**File:** `actions/claudia.py` — `create_claudia_prompt_action()`\n\nBefore calling `claudia_client.create_prompt_from_chat()`, fetch the chat and verify its status is appropriate for prompt generation. Currently the action blindly forwards the chat_id to the API, which does validate — but frank_bot should give a clearer, faster error message to ChatGPT rather than relying on a round-trip 404.\n\n**Acceptance criteria:**\n- If chat doesn't exist, return a clear message: \"Chat {id} not found. It may have been deleted or already converted to a prompt.\"\n- If chat is still `active` (not ended), return: \"Chat is still active. End the chat first before creating a prompt.\"\n- If chat already has a `promptId` set, return: \"A prompt was already generated from this chat: {promptId}\"\n\n### 2. Standardize exception handling across actions\n\n**Files:** `actions/claudia.py`, `services/claudia_client.py`\n\nCurrently some actions catch `ClaudiaAPIError` and re-raise as `ValueError`, losing the original error detail. Others let `ClaudiaAPIError` propagate directly. This inconsistency means error formatting for ChatGPT is unpredictable.\n\n**Acceptance criteria:**\n- All action functions should catch `ClaudiaAPIError` and return user-friendly strings (not raise exceptions), since these are OpenAI Action handlers that need to return text responses\n- Preserve the original error detail (status code, API message) in the returned string\n- Never let raw tracebacks or internal error types reach ChatGPT\n- Pattern: `try: ... except ClaudiaAPIError as e: return f\"Claudia API error ({e.status_code}): {e.detail}\"` — but phrased in natural language, not code-speak\n\n### 3. Expose chat_list in ClaudiaNamespace\n\n**File:** `meta/api.py` — `ClaudiaNamespace`\n\nThe `list_claudia_chats_action()` function exists in `actions/claudia.py` but isn't wired into the `ClaudiaNamespace` class in `meta/api.py`. This means it can't be called through the unified FrankAPI surface.\n\n**Acceptance criteria:**\n- Add a `chat_list(repo_name: str, status: str = None) -> str` method to `ClaudiaNamespace`\n- Should wrap `list_claudia_chats_action` with the same pattern as other namespace methods\n- Include in the namespace's docstring/help text\n\n### 4. Improve error context in create_prompt_from_chat client method\n\n**File:** `services/claudia_client.py` — `create_prompt_from_chat()`\n\nWhen the API returns an error, the client raises `ClaudiaAPIError` but the action handler catches it and converts to a generic `ValueError`, losing the specific API error detail (e.g., \"Chat not found\" vs \"Repository not found\" vs \"Queue full\").\n\n**Acceptance criteria:**\n- The `ClaudiaAPIError` should carry the HTTP status code and the API's `detail` field\n- The action handler should use this detail to construct a specific, helpful message\n- Example: instead of \"Failed to create prompt\" → \"Could not create prompt: the chat (f0192d65) was not found. It may have expired or been deleted.\"\n\n### 5. Add defensive handling for ChatGPT's stale state\n\n**File:** `actions/claudia.py`\n\nChatGPT sometimes holds onto IDs from earlier in the conversation that are no longer valid (e.g., a chat_id from a previous attempt). The actions should handle this gracefully.\n\n**Acceptance criteria:**\n- When a chat_id or prompt_id is not found (404), include helpful recovery guidance in the response: \"Chat not found. You can create a new chat with create_claudia_chat.\"\n- When a conflict occurs (409), explain what happened: \"This chat already has an active prompt generation. Check the queue status.\"\n- Never return raw UUIDs without context — always include the entity type and a hint about what to do next\n\n## Files to Modify\n\n1. `actions/claudia.py` — Primary target: validation logic, error handling standardization\n2. `services/claudia_client.py` — Ensure errors carry full context from API responses  \n3. `meta/api.py` — Wire up `chat_list` in `ClaudiaNamespace`\n\n## Success Criteria\n\n1. Running the chat → prompt → execute pipeline with an invalid chat_id returns a clear, actionable error message (not a traceback or generic \"failed\")\n2. All claudia action functions follow the same error handling pattern\n3. `ClaudiaNamespace.chat_list()` works and returns formatted chat list\n4. No regressions in the happy path (existing tests pass, if any)\n5. Error messages read like natural language that ChatGPT can relay to the user"
}
