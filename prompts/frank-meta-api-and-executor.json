{
  "$schema": "https://claudia.contrived.com/schemas/prompt.schema.json",
  "id": "frank-meta-api-and-executor",
  "title": "Frank Meta API and Script Executor",
  "description": "Add a programmable runtime to Frank that allows LLMs to write and execute Python scripts server-side",
  "authors": [
    { "name": "Sean", "type": "human" },
    { "name": "Claude", "type": "model" }
  ],
  "createdAt": "2026-01-29T03:15:00Z",
  "status": "ready",
  "tags": ["feature", "meta-api", "executor", "llm-tooling"],
  "content": "# Frank Meta API and Script Executor\n\n## Overview\n\nAdd a programmable runtime to Frank that allows an LLM to write and execute Python scripts server-side. This solves the problem of LLMs struggling with complex queries that require pagination, filtering, and aggregation - operations that are awkward or impossible through discrete action calls.\n\n**The core insight**: When an LLM needs to answer \"What hotels have I stayed at in San Francisco over the last 10 years?\", it currently has to make many individual API calls, each hitting response size limits. With a script executor, the LLM writes a Python loop that paginates, filters, and returns just the deduplicated list of hotel names.\n\n## Architecture\n\n### New Module: `meta/`\n\n```\nfrank_bot/\n├── meta/                     # NEW\n│   ├── __init__.py\n│   ├── api.py               # The FrankAPI class with .calendar, .swarm, etc.\n│   ├── executor.py          # Job execution with timeout/capture\n│   └── introspection.py     # Generates documentation for GET /frank/meta\n├── actions/                  # Existing - unchanged\n├── services/                 # Existing - unchanged\n└── server/\n    └── routes.py            # Add new endpoints\n```\n\n### New Endpoints\n\n| Endpoint | Method | Purpose |\n|----------|--------|--------|\n| `/frank/meta` | GET | Returns prose documentation of the Frank API |\n| `/frank/scripts` | GET | List all saved scripts with descriptions and parameters |\n| `/frank/scripts/{id}` | GET | Get a specific script's code |\n| `/frank/execute` | POST | Execute a script (new or existing), returns job_id immediately |\n| `/frank/jobs` | GET | List all job runs with status |\n| `/frank/jobs/{id}` | GET | Get job status, stdout, and result |\n\n### Data Storage\n\nScripts and jobs are stored on disk in a mounted volume at `./data/`:\n\n```\n./data/\n├── scripts/\n│   └── 2026-01-28T14-30-00-places-by-type-and-location.py\n└── jobs/\n    ├── 2026-01-28T14-35-00-places-by-type-and-location-run.json\n    └── 2026-01-28T16-00-00-places-by-type-and-location-run.json\n```\n\n**Script files**: Just the Python code with a docstring header.\n\n**Job files**: JSON containing params, stdout, stderr, result, status, timing.\n\n## The Frank API\n\n### Design: Namespace-Grouped\n\n```python\nfrank.calendar.events(day=None, max_results=10, ...)\nfrank.calendar.create(summary, start, end, ...)\nfrank.calendar.list()\n\nfrank.contacts.search(query)\n\nfrank.sms.send(recipient, message)\n\nfrank.swarm.checkins(year=None, category=None, with_companion=None, max_results=250, ...)\n\nfrank.ups.status()\n\nfrank.time.now(timezone=None)\n```\n\n### Implementation\n\nThe `FrankAPI` class wraps the existing services, presenting a **synchronous interface**. Internally it uses `asyncio.run()` to call the async actions. The LLM writes simple sync code.\n\n```python\nclass FrankAPI:\n    def __init__(self):\n        self.calendar = CalendarNamespace()\n        self.contacts = ContactsNamespace()\n        self.sms = SMSNamespace()\n        self.swarm = SwarmNamespace()\n        self.ups = UPSNamespace()\n        self.time = TimeNamespace()\n\nclass SwarmNamespace:\n    def checkins(self, year=None, category=None, with_companion=None, ...):\n        # Calls search_checkins_action synchronously\n        return asyncio.run(search_checkins_action({...}))\n```\n\n## Script Format\n\nScripts define a `main(frank, **params)` function. Parameters are passed as keyword arguments.\n\n```python\n\"\"\"\nFind places I've visited by type and location.\n\nParameters:\n  place_type: str - Category like \"hotel\", \"restaurant\", \"coffee shop\"\n  city: str - City name to filter by\n  person: str (optional) - Companion to filter by\n\nExample:\n  {\"place_type\": \"hotel\", \"city\": \"San Francisco\"}\n\"\"\"\ndef main(frank, place_type: str, city: str, person: str = None):\n    places = set()\n    for year in range(2014, 2027):\n        result = frank.swarm.checkins(category=place_type, year=year, max_results=250)\n        for c in result.get('checkins', []):\n            venue_city = (c.get('venue', {}).get('city') or '').lower()\n            if city.lower() not in venue_city:\n                continue\n            if person:\n                companions = [comp.get('display_name', '') for comp in c.get('companions', [])]\n                if not any(person.lower() in comp.lower() for comp in companions):\n                    continue\n            places.add(c['venue']['name'])\n    \n    print(f\"Found {len(places)} {place_type}s in {city}\")\n    return sorted(places)\n```\n\nThe docstring \"flower box\" is parsed to extract:\n- Description (first paragraph)\n- Parameters (from `Parameters:` section)\n- Example invocation (from `Example:` section)\n\n## Execution Model\n\n### Async Job Queue\n\nScripts run in background threads. The execute endpoint returns immediately with a job_id.\n\n**POST /frank/execute** accepts:\n\n```json\n// New script\n{\n  \"slug\": \"places-by-type-and-location\",\n  \"code\": \"def main(frank, place_type, city, person=None): ...\",\n  \"params\": {\"place_type\": \"hotel\", \"city\": \"San Francisco\"}\n}\n\n// Rerun existing script\n{\n  \"script_id\": \"2026-01-28T14-30-00-places-by-type-and-location\",\n  \"params\": {\"place_type\": \"restaurant\", \"city\": \"Austin\"}\n}\n```\n\n**Response:**\n```json\n{\n  \"job_id\": \"2026-01-28T14-35-00-places-by-type-and-location-run\",\n  \"status\": \"running\"\n}\n```\n\n### Job Status\n\n**GET /frank/jobs/{id}** returns:\n\n```json\n{\n  \"job_id\": \"2026-01-28T14-35-00-places-by-type-and-location-run\",\n  \"script_id\": \"2026-01-28T14-30-00-places-by-type-and-location\",\n  \"status\": \"completed\",\n  \"params\": {\"place_type\": \"hotel\", \"city\": \"San Francisco\"},\n  \"started_at\": \"2026-01-28T14:35:00Z\",\n  \"completed_at\": \"2026-01-28T14:35:45Z\",\n  \"stdout\": \"Found 12 hotels in San Francisco\\n\",\n  \"stderr\": \"\",\n  \"result\": [\"Argonaut Hotel\", \"Hotel Vitale\", ...],\n  \"error\": null\n}\n```\n\n### Timeout\n\n- **10 minute timeout** on script execution\n- When timeout occurs, the job status becomes `\"timeout\"` with a clear error message:\n  ```json\n  {\n    \"status\": \"timeout\",\n    \"error\": \"Script execution exceeded 10 minute timeout limit\"\n  }\n  ```\n\n### Concurrency\n\nMultiple scripts can run concurrently. This allows:\n- Fire off a long-running script\n- Immediately answer quick questions\n- Check back on the long script later\n\n## The Meta Endpoint\n\n**GET /frank/meta** returns README-style prose documentation in Markdown:\n\n```markdown\n# Frank Meta API\n\nFrank provides a Python runtime with access to your personal services.\n\n## Quick Start\n\nYour code should define a `main(frank, **params)` function:\n\n```python\ndef main(frank, city: str):\n    result = frank.swarm.checkins(max_results=50)\n    for c in result['checkins']:\n        if city.lower() in (c['venue'].get('city') or '').lower():\n            print(c['venue']['name'])\n    return \"Done\"\n```\n\n## Available Services\n\n### frank.calendar\n\n| Method | Signature | Description |\n|--------|-----------|-------------|\n| `events` | `(day=None, max_results=10, calendar_id=None)` | Get calendar events |\n| `create` | `(summary, start, end, description=None, ...)` | Create an event |\n| `list` | `()` | List available calendars |\n\n### frank.swarm\n\n| Method | Signature | Description |\n|--------|-----------|-------------|\n| `checkins` | `(year=None, category=None, with_companion=None, max_results=250)` | Search check-ins |\n\n**Tip**: For large date ranges, loop by year to avoid response size limits.\n\n### frank.sms\n\n| Method | Signature | Description |\n|--------|-----------|-------------|\n| `send` | `(recipient, message)` | Send SMS (recipient can be name or phone number) |\n\n### frank.contacts\n\n| Method | Signature | Description |\n|--------|-----------|-------------|\n| `search` | `(query)` | Search contacts by name |\n\n### frank.ups\n\n| Method | Signature | Description |\n|--------|-----------|-------------|\n| `status` | `()` | Get UPS battery status |\n\n### frank.time\n\n| Method | Signature | Description |\n|--------|-----------|-------------|\n| `now` | `(timezone=None)` | Get current time |\n\n## Execution\n\nPOST to `/frank/execute` with:\n\n```json\n{\n  \"slug\": \"my-script-name\",\n  \"code\": \"def main(frank, param1): ...\",\n  \"params\": {\"param1\": \"value\"}\n}\n```\n\nJobs run asynchronously. Poll `/frank/jobs/{job_id}` for status and results.\n```\n\n## Scripts Endpoint\n\n**GET /frank/scripts** returns:\n\n```json\n{\n  \"scripts\": [\n    {\n      \"id\": \"2026-01-28T14-30-00-places-by-type-and-location\",\n      \"description\": \"Find places I've visited by type and location.\",\n      \"parameters\": {\n        \"place_type\": {\"type\": \"str\", \"required\": true, \"description\": \"Category like hotel, restaurant\"},\n        \"city\": {\"type\": \"str\", \"required\": true, \"description\": \"City name to filter by\"},\n        \"person\": {\"type\": \"str\", \"required\": false, \"description\": \"Companion to filter by\"}\n      },\n      \"example\": {\"place_type\": \"hotel\", \"city\": \"San Francisco\"},\n      \"created_at\": \"2026-01-28T14:30:00Z\",\n      \"last_run\": \"2026-01-28T15:45:00Z\",\n      \"run_count\": 3\n    }\n  ]\n}\n```\n\n## Security\n\n- **Trust model**: Scripts run with full access, no sandboxing\n- Scripts are behind the same API key auth as other endpoints\n- Timeout protection prevents runaway scripts\n\n## Instructions Update\n\nUpdate `instructions_for_chatgpt.txt` to explain:\n\n1. **When to use execute**: For queries requiring pagination, filtering, aggregation, or combining multiple data sources. \"Execute is for getting data, not presenting it.\"\n\n2. **The workflow**: Write a script → execute it → read the result → present it nicely to the user (maps, tables, prose summary, etc.)\n\n3. **Reusable scripts**: Check `/frank/scripts` first - there may already be a script that does what you need with different parameters.\n\n4. **The meta endpoint**: Call `/frank/meta` to understand what capabilities are available.\n\nExample addition to instructions:\n\n```\n## Script Execution\n\nFor complex queries that would require multiple API calls, pagination, or aggregation, \nuse Frank's script executor:\n\n1. GET /frank/meta - Understand available capabilities\n2. GET /frank/scripts - Check for existing reusable scripts\n3. POST /frank/execute - Run a script (new or existing)\n4. GET /frank/jobs/{id} - Poll for results\n\nThink of execute as a way to GET DATA, not present it. Once you have the data,\npresent it appropriately (maps, charts, summaries, etc.) based on what the user asked.\n\nExample: \"What hotels have I stayed at in SF?\" \n- Execute a script that paginates through Swarm check-ins and deduplicates\n- Receive the list of hotel names\n- Present as a nicely formatted list or on a map\n```\n\n## File Naming Convention\n\n- **Scripts**: `{ISO8601-timestamp}-{slug}.py`\n  - Example: `2026-01-28T14-30-00-places-by-type-and-location.py`\n  \n- **Jobs**: `{ISO8601-timestamp}-{slug}-run.json`\n  - Example: `2026-01-28T14-35-00-places-by-type-and-location-run.json`\n\nThe timestamp is when the script was created (for scripts) or when the job was started (for jobs).\n\n## Docker Considerations\n\nThe `./data/` directory must be mounted as a volume so scripts and job results persist across container restarts:\n\n```yaml\nvolumes:\n  - ./data:/app/data\n```\n\n## Summary of Deliverables\n\n1. **`meta/api.py`** - FrankAPI class with namespace-grouped sync interface\n2. **`meta/executor.py`** - Job execution engine with timeout, stdout capture, background execution\n3. **`meta/introspection.py`** - Generates prose documentation from API inspection\n4. **`server/routes.py`** - Add 6 new endpoints\n5. **`instructions_for_chatgpt.txt`** - Update with script execution guidance\n6. **`docker-compose.yml`** - Ensure data volume is mounted"
}
