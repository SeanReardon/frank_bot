{
  "$schema": "https://claudia.contrived.com/schemas/prompt.schema.json",
  "id": "jorbs-autonomous-tasks",
  "title": "Jorbs: Autonomous Long-Lived Task System",
  "description": "Long-lived autonomous tasks that persist for hours/days, interacting with the real world via SMS, Telegram, and email",
  "authors": [
    {
      "name": "Sean",
      "type": "human"
    },
    {
      "name": "Claude",
      "type": "model"
    }
  ],
  "createdAt": "2026-01-29T00:00:00Z",
  "status": "ready",
  "tags": [
    "jorbs",
    "autonomous",
    "agent",
    "orchestration",
    "long-running"
  ],
  "content": "# Jorbs: Autonomous Long-Lived Task System\n\n## Overview\n\n\"Jorbs\" (jobs, but funnier) are long-lived autonomous tasks that frank_bot executes on Sean's behalf. Unlike ephemeral LLM chat conversations, jorbs persist for hours or days, interacting with the real world via SMS, Telegram, and email, with gpt-5.2 making decisions along the way.\n\n## The Three Parties\n\n1. **Sean** - Designs jorb plans (via ChatGPT or any LLM interface), checks progress, makes approval decisions\n2. **Frank_bot** - Orchestration hub: routing, persistence, policy enforcement, message capture\n3. **gpt-5.2** - The reasoning brain that processes events and decides actions (hardcoded model)\n\n## Architecture\n\n```\nfrank_bot/\n\u251c\u2500\u2500 services/\n\u2502   \u251c\u2500\u2500 jorb_storage.py       # SQLite persistence (NEW)\n\u2502   \u251c\u2500\u2500 agent_runner.py       # OpenAI API wrapper + context mgmt (NEW)\n\u2502   \u2514\u2500\u2500 email_service.py      # SMTP for digest + notifications (NEW)\n\u251c\u2500\u2500 actions/\n\u2502   \u2514\u2500\u2500 jorbs.py              # Jorb CRUD + approval actions (NEW)\n\u251c\u2500\u2500 prompts/\n\u2502   \u2514\u2500\u2500 agent_system.md       # System prompt for agent (EXISTS)\n\u2514\u2500\u2500 data/\n    \u2514\u2500\u2500 jorbs.db              # SQLite database (NEW, gitignored)\n```\n\n## Jorb Lifecycle\n\n```\nPLANNING \u2192 RUNNING \u2192 PAUSED \u2192 COMPLETE\n              \u2193         \u2193\n           FAILED   CANCELLED\n```\n\n- **planning**: Created but not started\n- **running**: Agent actively working\n- **paused**: Awaiting human decision (approval, clarification)\n- **complete**: Successfully finished\n- **failed**: Unrecoverable error\n- **cancelled**: User cancelled\n\n## Comms Affinity\n\nEach jorb defines which contacts it communicates with, and on which channel. This is the \"comms affinity\" - a single jorb might:\n- Use Telegram with Magic concierge\n- Use SMS with a hotel's front desk\n- Use Telegram with a friend helping coordinate\n\nThe `contacts` array in the jorb schema captures this:\n\n```json\n{\n  \"contacts\": [\n    { \"identifier\": \"@MagicConciergeBot\", \"channel\": \"telegram\", \"name\": \"Magic\" },\n    { \"identifier\": \"+14155551234\", \"channel\": \"sms\", \"name\": \"Hotel Nikko\" }\n  ]\n}\n```\n\nWhen a message arrives, frank_bot enriches it with contact lookup (Google Contacts reverse lookup for SMS, Telegram username/name) and presents ALL open jorbs + their full conversation threads to gpt-5.2. The LLM determines which jorb the message relates to based on:\n- Sender matching a jorb's contacts\n- Conversation context (if talking to party A about boats and party B about hotels, a new message from party A is probably the boats jorb)\n- Message content semantic matching\n\n## Service: jorb_storage.py\n\nSQLite-backed persistence for jorbs and their conversation history.\n\n### Schema\n\n```sql\nCREATE TABLE jorbs (\n    id TEXT PRIMARY KEY,\n    name TEXT NOT NULL,\n    status TEXT NOT NULL,\n    original_plan TEXT NOT NULL,\n    contacts_json TEXT,           -- JSON array of {identifier, channel, name}\n    progress_summary TEXT,\n    created_at TIMESTAMP,\n    updated_at TIMESTAMP,\n    paused_reason TEXT,\n    needs_approval_for TEXT,\n    awaiting TEXT\n);\n\nCREATE TABLE jorb_messages (\n    id INTEGER PRIMARY KEY AUTOINCREMENT,\n    jorb_id TEXT REFERENCES jorbs(id),\n    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n    direction TEXT NOT NULL,      -- 'inbound' or 'outbound'\n    channel TEXT NOT NULL,        -- 'telegram', 'sms', 'email'\n    sender TEXT NOT NULL,         -- identifier (phone, username)\n    sender_name TEXT,             -- resolved name from contact lookup\n    recipient TEXT NOT NULL,\n    content TEXT NOT NULL,\n    agent_reasoning TEXT          -- LLM's reasoning for outbound messages\n);\n\nCREATE TABLE jorb_checkpoints (\n    id INTEGER PRIMARY KEY AUTOINCREMENT,\n    jorb_id TEXT REFERENCES jorbs(id),\n    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n    summary TEXT NOT NULL,\n    token_count INTEGER\n);\n\nCREATE INDEX idx_messages_jorb ON jorb_messages(jorb_id);\nCREATE INDEX idx_messages_timestamp ON jorb_messages(timestamp);\n```\n\n### Methods\n\n```python\nclass JorbStorage:\n    async def create_jorb(name: str, plan: str, contacts: list[dict]) -> Jorb\n    async def get_jorb(jorb_id: str) -> Jorb | None\n    async def list_jorbs(status_filter: str | None = None) -> list[Jorb]\n    async def update_jorb(jorb_id: str, **updates) -> Jorb\n    async def add_message(jorb_id: str, message: JorbMessage) -> int\n    async def get_messages(jorb_id: str, limit: int = 50) -> list[JorbMessage]\n    async def get_open_jorbs_with_messages() -> list[JorbWithMessages]\n    async def add_checkpoint(jorb_id: str, summary: str, token_count: int) -> None\n```\n\n## Service: agent_runner.py\n\nWraps OpenAI API calls and manages context. Uses gpt-5.2 exclusively.\n\n### Core Loop: Processing Incoming Messages\n\nWhen a message arrives (SMS webhook or Telegram event), frank_bot:\n\n1. **Enriches** the message with contact lookup (name, Google Contact ID if known)\n2. **Fetches** all open jorbs with their full conversation threads\n3. **Sends** everything to gpt-5.2 with the agent system prompt\n4. **Receives** structured response: which jorb, reasoning, action to take\n5. **Executes** the action (send message, pause, complete)\n6. **Captures** both the inbound message AND any outbound response in the jorb's message history\n\n```python\nasync def process_incoming_message(event: IncomingEvent) -> AgentResponse:\n    \"\"\"\n    Process an incoming message from the world.\n    \n    1. Get all open jorbs with their full conversation threads\n    2. Build context with the new message (enriched with contact info)\n    3. Send to gpt-5.2 for decision\n    4. Execute the decision and capture messages\n    \"\"\"\n    # Fetch all open jorbs with messages\n    open_jorbs = await storage.get_open_jorbs_with_messages()\n    \n    # Build context for LLM\n    context = {\n        \"event\": {\n            \"channel\": event.channel,\n            \"sender\": event.sender,\n            \"sender_name\": event.sender_name,  # From contact lookup\n            \"content\": event.content,\n            \"timestamp\": event.timestamp.isoformat(),\n        },\n        \"open_jorbs\": [\n            {\n                \"id\": jorb.id,\n                \"name\": jorb.name,\n                \"status\": jorb.status,\n                \"plan\": jorb.original_plan,\n                \"contacts\": jorb.contacts,\n                \"awaiting\": jorb.awaiting,\n                \"messages\": [  # Full conversation thread\n                    {\n                        \"timestamp\": m.timestamp.isoformat(),\n                        \"direction\": m.direction,\n                        \"channel\": m.channel,\n                        \"sender\": m.sender_name or m.sender,\n                        \"content\": m.content,\n                    }\n                    for m in jorb.messages\n                ]\n            }\n            for jorb in open_jorbs\n        ],\n        \"policy\": JORB_POLICY,\n    }\n    \n    # Call gpt-5.2\n    response = await openai_client.chat.completions.create(\n        model=\"gpt-5.2\",\n        messages=[\n            {\"role\": \"system\", \"content\": AGENT_SYSTEM_PROMPT},\n            {\"role\": \"user\", \"content\": json.dumps(context)}\n        ],\n        response_format={\"type\": \"json_object\"}\n    )\n    \n    result = parse_agent_response(response)\n    \n    # Capture inbound message in the jorb\n    if result.jorb_id:\n        await storage.add_message(result.jorb_id, JorbMessage(\n            direction=\"inbound\",\n            channel=event.channel,\n            sender=event.sender,\n            sender_name=event.sender_name,\n            recipient=\"frank_bot\",\n            content=event.content,\n        ))\n    \n    # Execute action and capture outbound message\n    if result.action.type == \"send_message\":\n        send_result = await send_message(\n            channel=result.action.channel,\n            recipient=result.action.recipient,\n            content=result.action.content,\n        )\n        \n        if send_result.success:\n            await storage.add_message(result.jorb_id, JorbMessage(\n                direction=\"outbound\",\n                channel=result.action.channel,\n                sender=\"frank_bot\",\n                recipient=result.action.recipient,\n                content=result.action.content,\n                agent_reasoning=result.reasoning,\n            ))\n    \n    return result\n```\n\n### Sending Initial Messages (Jorb Kickoff)\n\nWhen a jorb is created with `start_immediately=True`, frank_bot needs to send the first message(s). This also goes through gpt-5.2:\n\n```python\nasync def kickoff_jorb(jorb: Jorb) -> None:\n    \"\"\"\n    Start a new jorb by asking gpt-5.2 for the initial action.\n    \"\"\"\n    context = {\n        \"event\": {\n            \"type\": \"jorb_created\",\n            \"jorb_id\": jorb.id,\n        },\n        \"jorb\": {\n            \"id\": jorb.id,\n            \"name\": jorb.name,\n            \"plan\": jorb.original_plan,\n            \"contacts\": jorb.contacts,\n            \"messages\": [],  # Empty - new jorb\n        },\n        \"instruction\": \"This jorb was just created. Send the first message to begin executing the plan.\",\n    }\n    \n    response = await openai_client.chat.completions.create(\n        model=\"gpt-5.2\",\n        messages=[\n            {\"role\": \"system\", \"content\": AGENT_SYSTEM_PROMPT},\n            {\"role\": \"user\", \"content\": json.dumps(context)}\n        ],\n        response_format={\"type\": \"json_object\"}\n    )\n    \n    result = parse_agent_response(response)\n    \n    # Execute initial action\n    if result.action.type == \"send_message\":\n        await execute_send_and_capture(jorb.id, result)\n```\n\n### Context Reset (\"Ralph Loop\")\n\nInstead of guessing when context is full, we use a simple rule:\n\n**Hard reset every 3 days, but only if there's been activity.**\n\nIf no messages have come from Sean or the world, the agent state stays the same - no need to burn tokens summarizing nothing.\n\nWhen a reset triggers:\n\n1. Ask gpt-5.2 to produce a structured handoff (inspired by Claudia's PRD/progress format)\n2. Append to `progress.txt` log file\n3. Start fresh session with:\n   - Original jorb plans\n   - Current jorb states (PRD-style)\n   - Last 100 lines of progress log\n\n```python\nasync def maybe_reset_context():\n    \"\"\"Called daily. Checks if 3 days have passed AND there's been activity.\"\"\"\n    if days_since_last_reset() >= 3 and has_activity_since_last_reset():\n        await perform_context_reset()\n\nasync def perform_context_reset():\n    # Ask gpt-5.2 to summarize current state\n    handoff = await generate_handoff(\n        prompt=\"\"\"Summarize the current state of all jorbs for your successor:\n        \n        For each active jorb, provide:\n        - Current status and what we're waiting for\n        - Key progress made\n        - Next steps when activity resumes\n        - Any blockers or concerns\n        \n        Also provide a progress entry for the log with:\n        - What was accomplished in this session\n        - Learnings or patterns noticed\n        - Recommendations for the next agent\n        \"\"\"\n    )\n    \n    # Append to progress log\n    await append_to_progress_log(handoff.progress_entry)\n    \n    # Update jorb states\n    for jorb_state in handoff.jorb_states:\n        await storage.update_jorb(jorb_state.id, summary=jorb_state.summary)\n    \n    # Reset for next session\n    record_reset_timestamp()\n```\n\n### Progress Log Format\n\nFile: `data/jorbs_progress.txt`\n\nInspired by Claudia's progress tracking:\n\n```markdown\n# Jorbs Progress Log\n\nThis file tracks activity by the frank_bot autonomous agent.\nEach entry documents what was accomplished and context for continuity.\n\n---\n\n## 2026-01-28: Session handoff (3-day reset)\n\n### Active Jorbs\n\n**jorb_47 - GDC Hotel Search** (PAUSED)\n- Status: Awaiting Sean's approval to book Hotel Nikko\n- Progress: Contacted Magic, got quotes for 3 hotels\n- Waiting for: Sean's decision on which hotel to book\n- Next steps: Once approved, confirm booking with Magic\n\n**jorb_52 - Flight price monitoring** (RUNNING)  \n- Status: Actively monitoring, no alerts triggered\n- Progress: Checked prices 12 times, all above threshold\n- Next steps: Continue monitoring until Feb 15 or price drops below $400\n\n### Session Summary\n- Processed 23 incoming messages across 4 channels\n- Made 8 outbound messages (5 Telegram, 3 SMS)\n- No purchases made (1 awaiting approval)\n- Spent ~45k tokens on LLM reasoning\n\n### Learnings\n- Magic responds faster in morning hours (PST)\n- Hotel Zetta doesn't respond to SMS, only phone calls\n- Consider adding a \"no response after 48h\" auto-escalation\n\n---\n```\n\n### Handoff Context for New Session\n\nWhen starting a new LLM session after reset:\n\n```python\ndef build_fresh_context():\n    return {\n        \"jorbs\": [\n            {\n                \"id\": j.id,\n                \"name\": j.name,\n                \"status\": j.status,\n                \"original_plan\": j.original_plan,\n                \"current_summary\": j.progress_summary,  # From handoff\n                \"awaiting\": j.awaiting,\n            }\n            for j in get_active_jorbs()\n        ],\n        \"progress_tail\": read_last_n_lines(\"data/jorbs_progress.txt\", 100),\n        \"policy\": current_policy,\n        \"last_reset\": last_reset_timestamp,\n    }\n```\n\n## Service: email_service.py\n\nSMTP service for notifications and daily digest.\n\n```python\nclass EmailService:\n    async def send(to, subject, body_html, body_text) -> None\n    async def send_daily_digest(jorbs: list[Jorb]) -> None\n    async def notify_jorb_paused(jorb: Jorb) -> None\n    async def notify_jorb_complete(jorb: Jorb) -> None\n```\n\n### Daily Digest\n\nSent from: frank_bot@contrived.com\nSent to: sean.reard@gmail.com\nSchedule: Daily at configured time (e.g., 8 AM)\n\nContents:\n1. Active jorbs summary (status, last activity)\n2. Completed jorbs (outcomes)\n3. All interactions log (chronological, grouped by jorb)\n4. Agent reasoning highlights\n5. Costs (tokens, SMS count)\n\n## Actions: jorbs.py\n\n```python\nasync def create_jorb(arguments) -> dict:\n    \"\"\"Create a new jorb with a plan.\"\"\"\n    # name: human-readable name\n    # plan: the full plan text\n    # start_immediately: bool (default True)\n\nasync def list_jorbs(arguments) -> dict:\n    \"\"\"List all jorbs, optionally filtered by status.\"\"\"\n    # status: \"open\" (running/paused), \"closed\" (complete/failed/cancelled), \"all\"\n\nasync def get_jorb(arguments) -> dict:\n    \"\"\"Get full details of a jorb including recent messages.\"\"\"\n    # jorb_id: the jorb to retrieve\n    # include_messages: bool (default True)\n    # message_limit: int (default 20)\n\nasync def get_jorb_messages(arguments) -> dict:\n    \"\"\"Get message history for a specific jorb.\"\"\"\n    # jorb_id: the jorb\n    # limit: number of messages (default 50)\n    # offset: pagination offset\n\nasync def approve_jorb(arguments) -> dict:\n    \"\"\"Approve a paused jorb to proceed.\"\"\"\n    # jorb_id: which jorb\n    # decision: what was decided (e.g., \"book Hotel Nikko\")\n\nasync def cancel_jorb(arguments) -> dict:\n    \"\"\"Cancel a jorb.\"\"\"\n    # jorb_id: which jorb\n    # reason: optional cancellation reason\n\nasync def brief_me(arguments) -> dict:\n    \"\"\"Get a briefing on activity since last check-in.\"\"\"\n    # Returns: needs_attention, activity_summary, highlights, pending_decisions\n    # Side effect: updates last_briefing_timestamp\n```\n\n## Routes\n\nAdd to server/routes.py:\n\n### Jorb Management\n- `GET /jorbs` - List jorbs (filterable by status: open, closed, all)\n- `GET /jorbs/create` - Create new jorb with plan\n- `GET /jorbs/{id}` - Get full jorb details (plan, progress, recent messages)\n- `GET /jorbs/{id}/messages` - Get message history for a jorb\n- `GET /jorbs/{id}/approve` - Approve paused jorb to proceed\n- `GET /jorbs/{id}/cancel` - Cancel a jorb\n\n### Briefing\n- `GET /jorbs/brief` - \"Brief me\" endpoint for Sean's LLM interface\n\nThe \"brief me\" endpoint is designed for any LLM chat interface to quickly catch up on what's been happening.\n\n## Message Debouncing\n\nIncoming messages are debounced per-conversation before processing:\n\n```python\nclass MessageBuffer:\n    debounce_seconds = {\n        \"telegram\": 60,  # Wait 60s for more messages\n        \"sms\": 30,\n        \"email\": 0,      # Emails are complete\n    }\n```\n\nWhen multiple messages arrive from the same sender within the debounce window, they're combined into a single event before sending to the LLM.\n\n## Policy Enforcement\n\n```python\nclass JorbPolicy:\n    max_spend_without_approval: float = 100.00\n    max_messages_per_hour: int = 20\n    require_approval_for: list = [\"purchase\", \"commit\", \"cancel\", \"share_info\"]\n    stale_jorb_hours: int = 48\n    max_jorb_duration_days: int = 14\n```\n\nThe LLM is informed of policy in its system prompt. Frank_bot also enforces:\n- Spending limits (track via jorb metadata)\n- Rate limiting (count messages per hour)\n- Auto-pause stale jorbs\n\n## Event Loop (Background Process)\n\nFrank_bot needs a background event loop that:\n\n1. **Listens for incoming messages** (Telegram via Telethon, SMS via Telnyx webhook)\n2. **Buffers and debounces** messages per-sender\n3. **Routes to LLM** when debounce timer expires\n4. **Executes LLM decisions** (send message, pause, complete)\n5. **Runs heartbeat** (check for stale jorbs, scheduled actions)\n6. **Sends daily digest** at configured time\n\nThis could be:\n- An asyncio background task started with the Starlette app\n- A separate process managed by the same docker-compose\n- Celery/similar if we need more robustness later\n\n## Environment Variables\n\nAdd to .env.example:\n\n```bash\n# OpenAI (for agent reasoning - always gpt-5.2)\nOPENAI_API_KEY=sk-...            # OpenAI API key\nAGENT_SPEND_LIMIT=100.00         # Max spend without approval (USD)\n\n# Debouncing\nDEBOUNCE_TELEGRAM_SECONDS=60\nDEBOUNCE_SMS_SECONDS=30\n\n# Email (for digest and notifications)\nSMTP_HOST=smtp.example.com\nSMTP_PORT=587\nSMTP_USER=frank_bot@contrived.com\nSMTP_PASSWORD=...\nDIGEST_EMAIL_TO=sean.reard@gmail.com\nDIGEST_TIME=08:00\n\n# Storage\nJORBS_DB_PATH=./data/jorbs.db\nJORBS_PROGRESS_LOG=./data/jorbs_progress.txt\n\n# Context management\nCONTEXT_RESET_DAYS=3\n```\n\nNote: The agent model is hardcoded to `gpt-5.2` in the code, not configurable via env var.\n\n## Dependencies\n\nAdd to pyproject.toml:\n```\nopenai = \"^1.0\"      # For agent reasoning (gpt-5.2)\naiosqlite = \"^0.19\"  # Async SQLite for jorb storage\naiosmtplib = \"^3.0\"  # Async SMTP for email digest\n```\n\n## Agent System Prompt\n\nSee `prompts/agent_system.md` for the full prompt. Key points:\n- LLM receives incoming event + all active jorb contexts\n- LLM responds with structured JSON (jorb_id, reasoning, action, update)\n- LLM knows when to pause for Sean's approval vs proceed\n- LLM understands message bundling (debouncing)\n\n## Success Criteria\n\n1. Can create a jorb with a plan via API\n2. Jorbs persist across frank_bot restarts (SQLite)\n3. Incoming messages (SMS, Telegram) are routed to LLM\n4. LLM can send messages via SMS/Telegram on behalf of jorbs\n5. LLM correctly pauses when policy requires approval\n6. Can list jorbs filtered by status (open/closed/all)\n7. Can drill down on jorb details including message history\n8. Can approve/cancel jorbs via API\n9. Daily digest email sent with all activity\n10. Context resets every 3 days (if there's been activity)\n11. Progress log maintained in Claudia-inspired format\n12. New LLM sessions receive last 100 lines of progress + current jorb states\n13. \"Brief me\" endpoint returns activity summary since last briefing\n14. Message debouncing prevents rapid-fire LLM calls\n\n## Example Flows\n\n### MVP Test: Simple Message Relay\n\nThe simplest jorb to verify the system works:\n\n1. Sean (via ChatGPT) creates a jorb:\n   ```\n   POST /actions/jorbs/create\n   {\n     \"name\": \"Say hi to Magic\",\n     \"plan\": \"Say hi to Magic for me. When they reply, reply back that I hope they're having a great day. Then the jorb is complete.\",\n     \"contacts\": [{\"identifier\": \"@MagicConciergeBot\", \"channel\": \"telegram\", \"name\": \"Magic\"}]\n   }\n   ```\n\n2. Frank_bot creates jorb, asks gpt-5.2 for initial action\n3. gpt-5.2 responds: send \"Hi! Sean wanted me to say hello \ud83d\udc4b\" to @MagicConciergeBot via Telegram\n4. Frank_bot sends message, captures it in jorb messages\n5. Hours later, Magic replies: \"Hey! Tell Sean hi back!\"\n6. Telegram event \u2192 frank_bot enriches with contact info \u2192 sends to gpt-5.2 with jorb context\n7. gpt-5.2 sees this is the \"Say hi to Magic\" jorb, responds: send \"Sean hopes you're having a great day!\" + mark jorb complete\n8. Frank_bot sends message, marks jorb complete\n9. Sean (new ChatGPT session) checks status:\n   ```\n   GET /actions/jorbs/jorb_1\n   ```\n   Response includes full message history:\n   ```json\n   {\n     \"id\": \"jorb_1\",\n     \"name\": \"Say hi to Magic\",\n     \"status\": \"complete\",\n     \"messages\": [\n       {\"direction\": \"outbound\", \"content\": \"Hi! Sean wanted me to say hello \ud83d\udc4b\", ...},\n       {\"direction\": \"inbound\", \"content\": \"Hey! Tell Sean hi back!\", ...},\n       {\"direction\": \"outbound\", \"content\": \"Sean hopes you're having a great day!\", ...}\n     ]\n   }\n   ```\n\n### Full Example: GDC Hotel Search\n\n1. Sean + ChatGPT design a plan: \"Find GDC hotel, contact Magic, get quotes\"\n2. ChatGPT calls `POST /actions/jorbs/create` with the plan and contacts\n3. Frank_bot creates jorb, gpt-5.2 sends first Telegram message to Magic\n4. Hours later, Magic replies with quotes\n5. Telegram event \u2192 debounce \u2192 gpt-5.2 receives bundled messages with full jorb context\n6. gpt-5.2 decides to pause (booking requires approval), provides reasoning\n7. Sean checks in via ChatGPT: `GET /actions/jorbs/{id}` - sees messages + status\n8. ChatGPT shows options, Sean approves\n9. `GET /actions/jorbs/{id}/approve?decision=book+nikko`\n10. gpt-5.2 sends booking confirmation to Magic\n11. Jorb marked complete with outcome summary\n12. Daily digest includes full interaction log\n\n## Reference\n\n- Design doc: docs/AGENT_ORCHESTRATION.md\n- Agent prompt: prompts/agent_system.md\n- Existing SMS pattern: services/telnyx_sms.py, actions/sms.py\n- Telegram client: services/telegram_client.py (DONE)\n- SMS storage: services/sms_storage.py (DONE)\n- Contact lookup: services/contact_lookup.py (DONE)\n\n## Prerequisites (All Complete)\n\nThese are now implemented:\n1. \u2705 Telegram integration (services/telegram_client.py) - Telethon client for send/receive\n2. \u2705 Telnyx SMS integration - Send + inbound webhook + storage\n3. \u2705 Contact lookup - Phone \u2192 Google Contact reverse lookup\n4. \u2705 Telegram Bot - For notifications\n\n## What Needs to Be Built\n\n1. `services/jorb_storage.py` - SQLite persistence for jorbs + messages\n2. `services/agent_runner.py` - OpenAI wrapper, context building, action execution\n3. `actions/jorbs.py` - CRUD actions (create, get, list, approve, cancel, brief_me)\n4. `server/routes.py` additions - Routes for jorb actions\n5. `openapi/spec.json` additions - OpenAPI spec for jorb endpoints\n6. Background message routing - Connect webhooks to agent_runner\n7. `services/email_service.py` - Daily digest (can defer)\n8. Update `schemas/jorb.schema.json` - Add `messages` array if storing inline",
  "executions": [
    {
      "executedAt": "2026-01-30T05:23:19.526333Z",
      "model": "claude-opus",
      "prdIds": [
        "frank_bot-00051",
        "frank_bot-00052",
        "frank_bot-00053",
        "frank_bot-00054",
        "frank_bot-00055",
        "frank_bot-00056",
        "frank_bot-00057",
        "frank_bot-00058",
        "frank_bot-00059",
        "frank_bot-00060",
        "frank_bot-00061",
        "frank_bot-00062",
        "frank_bot-00063",
        "frank_bot-00064",
        "frank_bot-00065",
        "frank_bot-00066",
        "frank_bot-00067",
        "frank_bot-00068",
        "frank_bot-00069",
        "frank_bot-00070",
        "frank_bot-00071",
        "frank_bot-00072",
        "frank_bot-00073"
      ],
      "tokensUsed": 8108
    }
  ]
}
