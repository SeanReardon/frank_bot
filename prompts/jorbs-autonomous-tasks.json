{
  "$schema": "https://claudia.contrived.com/schemas/prompt.schema.json",
  "id": "jorbs-autonomous-tasks",
  "title": "Jorbs: Autonomous Long-Lived Task System",
  "description": "Long-lived autonomous tasks that persist for hours/days, interacting with the real world via SMS, Telegram, and email",
  "authors": [
    { "name": "Sean", "type": "human" },
    { "name": "Claude", "type": "model" }
  ],
  "createdAt": "2026-01-29T00:00:00Z",
  "status": "ready",
  "tags": ["jorbs", "autonomous", "agent", "orchestration", "long-running"],
  "blockedBy": "telegram-integration",
  "content": "# Jorbs: Autonomous Long-Lived Task System\n\n## Overview\n\n\"Jorbs\" (jobs, but funnier) are long-lived autonomous tasks that frank_bot executes on Sean's behalf. Unlike ephemeral LLM chat conversations, jorbs persist for hours or days, interacting with the real world via SMS, Telegram, and email, with an LLM making decisions along the way.\n\n## The Three Parties\n\n1. **Sean** - Designs jorb plans (via any LLM chat interface), checks progress, makes approval decisions\n2. **Frank_bot** - Orchestration hub: routing, persistence, policy enforcement\n3. **LLM** - The reasoning brain that processes events and decides actions (swappable provider)\n\n## Architecture\n\n```\nfrank_bot/\n├── services/\n│   ├── jorb_storage.py       # SQLite persistence (NEW)\n│   ├── agent_runner.py       # LLM API wrapper + context mgmt (NEW)\n│   └── email_service.py      # SMTP for digest + notifications (NEW)\n├── actions/\n│   └── jorbs.py              # Jorb CRUD + approval actions (NEW)\n├── prompts/\n│   └── agent_system.md       # System prompt for agent (EXISTS)\n└── data/\n    └── jorbs.db              # SQLite database (NEW, gitignored)\n```\n\n## Jorb Lifecycle\n\n```\nPLANNING → RUNNING → PAUSED → COMPLETE\n              ↓         ↓\n           FAILED   CANCELLED\n```\n\n- **planning**: Created but not started\n- **running**: Agent actively working\n- **paused**: Awaiting human decision (approval, clarification)\n- **complete**: Successfully finished\n- **failed**: Unrecoverable error\n- **cancelled**: User cancelled\n\n## Service: jorb_storage.py\n\nSQLite-backed persistence for jorbs and their history.\n\n### Schema\n\n```sql\nCREATE TABLE jorbs (\n    id TEXT PRIMARY KEY,\n    name TEXT NOT NULL,\n    status TEXT NOT NULL,\n    original_plan TEXT NOT NULL,\n    progress_summary TEXT,\n    created_at TIMESTAMP,\n    updated_at TIMESTAMP,\n    paused_reason TEXT,\n    needs_approval_for TEXT\n);\n\nCREATE TABLE jorb_messages (\n    id INTEGER PRIMARY KEY,\n    jorb_id TEXT REFERENCES jorbs(id),\n    timestamp TIMESTAMP,\n    direction TEXT,  -- 'inbound' or 'outbound'\n    channel TEXT,    -- 'telegram', 'sms', 'email'\n    sender TEXT,\n    recipient TEXT,\n    content TEXT,\n    agent_reasoning TEXT\n);\n\nCREATE TABLE jorb_checkpoints (\n    id INTEGER PRIMARY KEY,\n    jorb_id TEXT REFERENCES jorbs(id),\n    timestamp TIMESTAMP,\n    summary TEXT,\n    token_count INTEGER\n);\n```\n\n### Methods\n\n```python\nclass JorbStorage:\n    async def create_jorb(name, plan) -> Jorb\n    async def get_jorb(jorb_id) -> Jorb\n    async def list_jorbs(status_filter=None) -> list[Jorb]\n    async def update_jorb(jorb_id, **updates) -> Jorb\n    async def add_message(jorb_id, message) -> None\n    async def get_messages(jorb_id, limit=50) -> list[Message]\n    async def add_checkpoint(jorb_id, summary, token_count) -> None\n```\n\n## Service: agent_runner.py\n\nWraps LLM API calls and manages context. Provider-agnostic design.\n\n### Core Loop\n\n```python\nasync def process_event(event: IncomingEvent, all_jorbs: list[Jorb]) -> AgentResponse:\n    \"\"\"\n    Given an incoming event and all active jorbs, ask the LLM what to do.\n    \"\"\"\n    context = build_context(event, all_jorbs)\n    \n    response = await llm_client.chat(\n        model=settings.AGENT_MODEL,\n        messages=[\n            {\"role\": \"system\", \"content\": AGENT_SYSTEM_PROMPT},\n            {\"role\": \"user\", \"content\": json.dumps(context)}\n        ],\n        response_format={\"type\": \"json_object\"}\n    )\n    \n    return parse_agent_response(response)\n```\n\n### Context Reset (\"Ralph Loop\")\n\nInstead of guessing when context is full, we use a simple rule:\n\n**Hard reset every 3 days, but only if there's been activity.**\n\nIf no messages have come from Sean or the world, the agent state stays the same - no need to burn tokens summarizing nothing.\n\nWhen a reset triggers:\n\n1. Ask current LLM to produce a structured handoff (inspired by Claudia's PRD/progress format)\n2. Append to `progress.txt` log file\n3. Start fresh session with:\n   - Original jorb plans\n   - Current jorb states (PRD-style)\n   - Last 100 lines of progress log\n\n```python\nasync def maybe_reset_context():\n    \"\"\"Called daily. Checks if 3 days have passed AND there's been activity.\"\"\"\n    if days_since_last_reset() >= 3 and has_activity_since_last_reset():\n        await perform_context_reset()\n\nasync def perform_context_reset():\n    # Ask LLM to summarize current state\n    handoff = await llm_client.generate_handoff(\n        prompt=\"\"\"Summarize the current state of all jorbs for your successor:\n        \n        For each active jorb, provide:\n        - Current status and what we're waiting for\n        - Key progress made\n        - Next steps when activity resumes\n        - Any blockers or concerns\n        \n        Also provide a progress entry for the log with:\n        - What was accomplished in this session\n        - Learnings or patterns noticed\n        - Recommendations for the next agent\n        \"\"\"\n    )\n    \n    # Append to progress log\n    await append_to_progress_log(handoff.progress_entry)\n    \n    # Update jorb states\n    for jorb_state in handoff.jorb_states:\n        await storage.update_jorb(jorb_state.id, summary=jorb_state.summary)\n    \n    # Reset for next session\n    record_reset_timestamp()\n```\n\n### Progress Log Format\n\nFile: `data/jorbs_progress.txt`\n\nInspired by Claudia's progress tracking:\n\n```markdown\n# Jorbs Progress Log\n\nThis file tracks activity by the frank_bot autonomous agent.\nEach entry documents what was accomplished and context for continuity.\n\n---\n\n## 2026-01-28: Session handoff (3-day reset)\n\n### Active Jorbs\n\n**jorb_47 - GDC Hotel Search** (PAUSED)\n- Status: Awaiting Sean's approval to book Hotel Nikko\n- Progress: Contacted Magic, got quotes for 3 hotels\n- Waiting for: Sean's decision on which hotel to book\n- Next steps: Once approved, confirm booking with Magic\n\n**jorb_52 - Flight price monitoring** (RUNNING)  \n- Status: Actively monitoring, no alerts triggered\n- Progress: Checked prices 12 times, all above threshold\n- Next steps: Continue monitoring until Feb 15 or price drops below $400\n\n### Session Summary\n- Processed 23 incoming messages across 4 channels\n- Made 8 outbound messages (5 Telegram, 3 SMS)\n- No purchases made (1 awaiting approval)\n- Spent ~45k tokens on LLM reasoning\n\n### Learnings\n- Magic responds faster in morning hours (PST)\n- Hotel Zetta doesn't respond to SMS, only phone calls\n- Consider adding a \"no response after 48h\" auto-escalation\n\n---\n```\n\n### Handoff Context for New Session\n\nWhen starting a new LLM session after reset:\n\n```python\ndef build_fresh_context():\n    return {\n        \"jorbs\": [\n            {\n                \"id\": j.id,\n                \"name\": j.name,\n                \"status\": j.status,\n                \"original_plan\": j.original_plan,\n                \"current_summary\": j.progress_summary,  # From handoff\n                \"awaiting\": j.awaiting,\n            }\n            for j in get_active_jorbs()\n        ],\n        \"progress_tail\": read_last_n_lines(\"data/jorbs_progress.txt\", 100),\n        \"policy\": current_policy,\n        \"last_reset\": last_reset_timestamp,\n    }\n```\n\n## Service: email_service.py\n\nSMTP service for notifications and daily digest.\n\n```python\nclass EmailService:\n    async def send(to, subject, body_html, body_text) -> None\n    async def send_daily_digest(jorbs: list[Jorb]) -> None\n    async def notify_jorb_paused(jorb: Jorb) -> None\n    async def notify_jorb_complete(jorb: Jorb) -> None\n```\n\n### Daily Digest\n\nSent from: frank_bot@contrived.com\nSent to: sean.reard@gmail.com\nSchedule: Daily at configured time (e.g., 8 AM)\n\nContents:\n1. Active jorbs summary (status, last activity)\n2. Completed jorbs (outcomes)\n3. All interactions log (chronological, grouped by jorb)\n4. Agent reasoning highlights\n5. Costs (tokens, SMS count)\n\n## Actions: jorbs.py\n\n```python\nasync def create_jorb(arguments) -> dict:\n    \"\"\"Create a new jorb with a plan.\"\"\"\n    # name: human-readable name\n    # plan: the full plan text\n    # start_immediately: bool (default True)\n\nasync def list_jorbs(arguments) -> dict:\n    \"\"\"List all jorbs, optionally filtered by status.\"\"\"\n    # status: \"open\" (running/paused), \"closed\" (complete/failed/cancelled), \"all\"\n\nasync def get_jorb(arguments) -> dict:\n    \"\"\"Get full details of a jorb including recent messages.\"\"\"\n    # jorb_id: the jorb to retrieve\n    # include_messages: bool (default True)\n    # message_limit: int (default 20)\n\nasync def get_jorb_messages(arguments) -> dict:\n    \"\"\"Get message history for a specific jorb.\"\"\"\n    # jorb_id: the jorb\n    # limit: number of messages (default 50)\n    # offset: pagination offset\n\nasync def approve_jorb(arguments) -> dict:\n    \"\"\"Approve a paused jorb to proceed.\"\"\"\n    # jorb_id: which jorb\n    # decision: what was decided (e.g., \"book Hotel Nikko\")\n\nasync def cancel_jorb(arguments) -> dict:\n    \"\"\"Cancel a jorb.\"\"\"\n    # jorb_id: which jorb\n    # reason: optional cancellation reason\n\nasync def brief_me(arguments) -> dict:\n    \"\"\"Get a briefing on activity since last check-in.\"\"\"\n    # Returns: needs_attention, activity_summary, highlights, pending_decisions\n    # Side effect: updates last_briefing_timestamp\n```\n\n## Routes\n\nAdd to server/routes.py:\n\n### Jorb Management\n- `GET /jorbs` - List jorbs (filterable by status: open, closed, all)\n- `GET /jorbs/create` - Create new jorb with plan\n- `GET /jorbs/{id}` - Get full jorb details (plan, progress, recent messages)\n- `GET /jorbs/{id}/messages` - Get message history for a jorb\n- `GET /jorbs/{id}/approve` - Approve paused jorb to proceed\n- `GET /jorbs/{id}/cancel` - Cancel a jorb\n\n### Briefing\n- `GET /jorbs/brief` - \"Brief me\" endpoint for Sean's LLM interface\n\nThe \"brief me\" endpoint is designed for any LLM chat interface to quickly catch up on what's been happening.\n\n## Message Debouncing\n\nIncoming messages are debounced per-conversation before processing:\n\n```python\nclass MessageBuffer:\n    debounce_seconds = {\n        \"telegram\": 60,  # Wait 60s for more messages\n        \"sms\": 30,\n        \"email\": 0,      # Emails are complete\n    }\n```\n\nWhen multiple messages arrive from the same sender within the debounce window, they're combined into a single event before sending to the LLM.\n\n## Policy Enforcement\n\n```python\nclass JorbPolicy:\n    max_spend_without_approval: float = 100.00\n    max_messages_per_hour: int = 20\n    require_approval_for: list = [\"purchase\", \"commit\", \"cancel\", \"share_info\"]\n    stale_jorb_hours: int = 48\n    max_jorb_duration_days: int = 14\n```\n\nThe LLM is informed of policy in its system prompt. Frank_bot also enforces:\n- Spending limits (track via jorb metadata)\n- Rate limiting (count messages per hour)\n- Auto-pause stale jorbs\n\n## Event Loop (Background Process)\n\nFrank_bot needs a background event loop that:\n\n1. **Listens for incoming messages** (Telegram via Telethon, SMS via Telnyx webhook)\n2. **Buffers and debounces** messages per-sender\n3. **Routes to LLM** when debounce timer expires\n4. **Executes LLM decisions** (send message, pause, complete)\n5. **Runs heartbeat** (check for stale jorbs, scheduled actions)\n6. **Sends daily digest** at configured time\n\nThis could be:\n- An asyncio background task started with the Starlette app\n- A separate process managed by the same docker-compose\n- Celery/similar if we need more robustness later\n\n## Environment Variables\n\nAdd to .env.example:\n\n```bash\n# LLM Provider (swappable)\nLLM_PROVIDER=openai              # or \"anthropic\", \"local\", etc.\nLLM_API_KEY=sk-...               # Provider-specific key\nAGENT_MODEL=gpt-5.2              # Model to use for agent reasoning\nAGENT_SPEND_LIMIT=100.00\n\n# Debouncing\nDEBOUNCE_TELEGRAM_SECONDS=60\nDEBOUNCE_SMS_SECONDS=30\n\n# Email (for digest and notifications)\nSMTP_HOST=smtp.example.com\nSMTP_PORT=587\nSMTP_USER=frank_bot@contrived.com\nSMTP_PASSWORD=...\nDIGEST_EMAIL_TO=sean.reard@gmail.com\nDIGEST_TIME=08:00\n\n# Storage\nJORBS_DB_PATH=./data/jorbs.db\nJORBS_PROGRESS_LOG=./data/jorbs_progress.txt\n\n# Context management\nCONTEXT_RESET_DAYS=3\n```\n\n## Dependencies\n\nAdd to pyproject.toml:\n```\nopenai = \"^1.0\"      # Default provider (swappable)\nanthropic = \"^0.18\"  # Alternative provider\naiosqlite = \"^0.19\"\naiosmtplib = \"^3.0\"\n```\n\n## Agent System Prompt\n\nSee `prompts/agent_system.md` for the full prompt. Key points:\n- LLM receives incoming event + all active jorb contexts\n- LLM responds with structured JSON (jorb_id, reasoning, action, update)\n- LLM knows when to pause for Sean's approval vs proceed\n- LLM understands message bundling (debouncing)\n\n## Success Criteria\n\n1. Can create a jorb with a plan via API\n2. Jorbs persist across frank_bot restarts (SQLite)\n3. Incoming messages (SMS, Telegram) are routed to LLM\n4. LLM can send messages via SMS/Telegram on behalf of jorbs\n5. LLM correctly pauses when policy requires approval\n6. Can list jorbs filtered by status (open/closed/all)\n7. Can drill down on jorb details including message history\n8. Can approve/cancel jorbs via API\n9. Daily digest email sent with all activity\n10. Context resets every 3 days (if there's been activity)\n11. Progress log maintained in Claudia-inspired format\n12. New LLM sessions receive last 100 lines of progress + current jorb states\n13. \"Brief me\" endpoint returns activity summary since last briefing\n14. Message debouncing prevents rapid-fire LLM calls\n\n## Example Flow\n\n1. Sean + LLM (any chat interface) design a plan: \"Find GDC hotel, contact Magic, get quotes\"\n2. LLM calls `POST /jorbs/create` with the plan\n3. Frank_bot creates jorb, LLM sends first Telegram message to Magic\n4. Hours later, Magic replies with quotes\n5. Telegram event → debounce → LLM receives bundled messages\n6. LLM decides to pause (booking requires approval)\n7. Sean checks in via LLM chat: `GET /jorbs/{id}`\n8. LLM shows options, Sean approves\n9. `GET /jorbs/{id}/approve?decision=book+nikko`\n10. LLM sends booking confirmation to Magic\n11. Jorb marked complete\n12. Daily digest includes full interaction log\n\n## Reference\n\n- Design doc: docs/AGENT_ORCHESTRATION.md\n- Agent prompt: prompts/agent_system.md\n- Existing SMS pattern: services/telnyx_sms.py, actions/sms.py\n- Telethon integration: prompts/telegram-integration.json (prerequisite)\n\n## Prerequisites\n\nThis jorbs system depends on:\n1. Telegram integration (prompts/telegram-integration.json) - for Telegram messaging\n2. Existing Telnyx SMS integration - for SMS messaging\n3. LLM API access - for agent decisions (any supported provider)\n\nImplement Telegram integration first, then jorbs.",
  "executions": []
}
